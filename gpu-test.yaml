kind: Job
apiVersion: batch/v1
metadata:
  name: gpu-test
  namespace: sw77-hpc-test
  labels:
    app: gpu-test
    app.kubernetes.io/component: gpu-test
    app.kubernetes.io/instance: gpu-test
    app.kubernetes.io/name: gpu-test
    app.openshift.io/runtime-namespace: sw77-hpc-test
spec:
  parallelism: 1
  completions: 1
  completionMode: Indexed
  ttlSecondsAfterFinished: 120
  selector:
    matchLabels:

  template:
    metadata:
      labels:
        app: gpu-test
        deployment: gpu-test
    spec:
      volumes:
        - name: sw77-shared
          persistentVolumeClaim:
            claimName: sw77-shared
        - name: sw77-tmp
          emptyDir:
            sizeLimit: 100Gi
        - name: cache-volume
          emptyDir:
            medium: Memory
            sizeLimit: 1000Mi
      containers:
        - resources:
            limits:
              cpu: '4'
              memory: 50Gi
              nvidia.com/gpu: "2"
            requests:
              cpu: '4'
              memory: 50Gi
              nvidia.com/gpu: "2"
          name: gpu-test
          volumeMounts:
            - name: sw77-shared
              mountPath: /work
            - mountPath: /scratch
              name: sw77-tmp
            - mountPath: /dev/shm
              name: cache-volume
          image: >-
            registry.cloud.rt.nyu.edu/sw77/chemistry:20241207
          env:
            - name: TZ
              value: America/New_York
            - name: HOME
              value: /work/wang
            - name: MY_POD_INDEX
              valueFrom:
                fieldRef:
                  fieldPath: 'metadata.labels[''batch.kubernetes.io/job-completion-index'']'
          command:
            - /bin/bash
            - '-c'
            - |
              sleep infinity 
              pip install h5py pytorch-lightning einops && \
              cd /scratch && cp -rp /work/wang/promoters_v2-20241101 . && \
              cd promoters_v2-20241101 && python train_pylightning.py 
      restartPolicy: Never
      tolerations:
      - effect: NoSchedule
        key: nvidia.com/usage
        operator: Equal
        value: dedicated
      - effect: NoSchedule
        key: nvidia.com/gpu
        operator: Exists

# pytorch/pytorch:2.5.1-cuda12.4-cudnn9-runtime
# registry.cloud.rt.nyu.edu/sw77/cuda:12.6.3-ubuntu24.04-20250103